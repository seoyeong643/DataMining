{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CSE 572: Lab 3\n",
        "\n",
        "In this lab, you will practice implementing to handle imbalanced datasets. You will use methods such as upsampling, downsampling, and SMOTE to balance/augment different datasets (matrix, image, text data) and evaluate how these techniques affect model performance.\n",
        "\n",
        "To execute and make changes to this notebook, click File > Save a copy to save your own version in your Google Drive or Github. Read the step-by-step instructions below carefully. To execute the code, click on each cell below and press the SHIFT-ENTER keys simultaneously or by clicking the Play button.\n",
        "\n",
        "When you finish executing all code/exercises, save your notebook then download a copy (.ipynb file). Submit 1) a link to your Colab notebook, 2) the .ipynb file, and **3) a pdf of the executed notebook** on Canvas.\n",
        "\n",
        "To generate a pdf of the notebook, click File > Print > Save as PDF."
      ],
      "metadata": {
        "id": "8Sy_5qsyNzIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PUT YOUR GROUP INFO HERE**\n",
        "\n",
        "| Group number | August Group XXX |            |\n",
        "|--------------|------------------|------------|\n",
        "| Member 1     | NAME             | ASURITE ID |\n",
        "| Member 2     |                  |            |\n",
        "| Member 3     |                  |            |\n",
        "| Member 4     |                  |            |"
      ],
      "metadata": {
        "id": "J87jdBwNeDzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.datasets import make_classification\n"
      ],
      "metadata": {
        "id": "TdowkfsSOtRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load Dataset\n",
        "# Using an imbalanced dataset from scikit-learn\n",
        "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.9, 0.1],\n",
        "                           n_informative=3, n_redundant=1, flip_y=0,\n",
        "                           n_features=5, n_clusters_per_class=1,\n",
        "                           n_samples=1000, random_state=42)\n",
        "data = pd.DataFrame(X, columns=[f'feature{i}' for i in range(1, X.shape[1] + 1)])\n",
        "data['label'] = y\n",
        "\n",
        "print(\"Original Dataset Class Distribution:\")\n",
        "print(data['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "qW251DWnOuyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train-Test Split\n",
        "X = data.drop('label', axis=1)\n",
        "y = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "7yHfdRYzO0D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balancing Techniques"
      ],
      "metadata": {
        "id": "Fk9nKJYYO-J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Upsampling Minority Class\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "minority = train_data[train_data['label'] == 1]\n",
        "majority = train_data[train_data['label'] == 0]\n",
        "minority_upsampled = resample(minority, replace=True, n_samples=len(majority), random_state=42)\n",
        "upsampled_data = pd.concat([majority, minority_upsampled])"
      ],
      "metadata": {
        "id": "dBgLRHxrO4yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Upsampled Dataset Class Distribution:\")\n",
        "# Your Code Here\n"
      ],
      "metadata": {
        "id": "hvW3TVykPhks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Downsampling Majority Class\n",
        "majority_downsampled = resample(majority, replace=False, n_samples=len(minority), random_state=42)\n",
        "downsampled_data = pd.concat([majority_downsampled, minority])"
      ],
      "metadata": {
        "id": "MS-7xtbCPqIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downsampled Dataset Class Distribution:\")\n",
        "# Your Code Here\n"
      ],
      "metadata": {
        "id": "boeqxWKoPv-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "C0nXhPr4P1F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SMOTE Dataset Class Distribution:\")\n",
        "# Your Code Here"
      ],
      "metadata": {
        "id": "aY8viTv5P7tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train Classifiers and Evaluate\n",
        "\n",
        "## Helper function to train and evaluate a model\n",
        "def train_and_evaluate(X_train, y_train, X_test, y_test, method_name):\n",
        "    print(f\"\\nResults for {method_name}:\")\n",
        "    model = LogisticRegression(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Train and evaluate on original data\n",
        "train_and_evaluate(X_train, y_train, X_test, y_test, \"Original Dataset\")\n",
        "\n",
        "# Train and evaluate on upsampled data\n",
        "train_and_evaluate(upsampled_data.drop('label', axis=1), upsampled_data['label'], X_test, y_test, \"Upsampled Dataset\")\n",
        "\n",
        "# Train and evaluate on downsampled data\n",
        "train_and_evaluate(downsampled_data.drop('label', axis=1), downsampled_data['label'], X_test, y_test, \"Downsampled Dataset\")\n",
        "\n",
        "# Train and evaluate on SMOTE data\n",
        "train_and_evaluate(X_smote, y_smote, X_test, y_test, \"SMOTE Dataset\")"
      ],
      "metadata": {
        "id": "U_dywjQPRhgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1: Analyze and compare the results from the different balancing techniques. Which method provided the best balance between precision, recall, and F1-score?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "YOUR ANSWER HERE\n"
      ],
      "metadata": {
        "id": "qwv1LNwdRwu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Data Augmentation\n",
        "\n"
      ],
      "metadata": {
        "id": "mypTaU1_H7n3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs"
      ],
      "metadata": {
        "id": "9TbDf1vXI0g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies\n",
        "!pip install imgaug --quiet\n",
        "!pip install albumentations --quiet\n",
        "!pip install torchvision --quiet\n",
        "!pip install opencv-python --quiet"
      ],
      "metadata": {
        "id": "8hEb40LrIzlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Env Config"
      ],
      "metadata": {
        "id": "xKlmKbbjJqVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import imgaug.augmenters as iaa\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "0eXFCebcJoVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Env params\n",
        "\n",
        "IMG_PATH = 'https://www.gstatic.com/webp/gallery/1.jpg' #@param"
      ],
      "metadata": {
        "id": "jcxL5K8wJS3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Fetch the image from the URL\n",
        "response = requests.get(IMG_PATH, stream=True).raw\n",
        "image = np.asarray(bytearray(response.read()), dtype=\"uint8\")\n",
        "image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "\n",
        "# Convert from BGR to RGB for matplotlib\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.title(\"Original Image\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l7qrxcBtKEzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Augmentation Options"
      ],
      "metadata": {
        "id": "PjCYzD3EJtPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Flipping\n",
        "\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "# flip horizontally\n",
        "flip_aug = iaa.Fliplr(1.0)  # 1.0 means always flip\n",
        "\n",
        "augmented_image = flip_aug.augment_image(image)\n",
        "\n",
        "plt.imshow(augmented_image)\n",
        "plt.title(\"Horizontally Flipped Image\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N7YNcCdxJ8MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Option 2: Rotation\n",
        "rotate_aug = iaa.Affine(rotate=(90)) # rotating 90 degrees, if you pass in a tupple, rotate will pick a random value between your two params\n",
        "\n",
        "augmented_image = rotate_aug.augment_image(image)\n",
        "\n",
        "plt.imshow(augmented_image)\n",
        "plt.title(\"Rotated Image\")\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "poFdTHdTKwRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Brightness Adjustment\n",
        "\n",
        "brightness_aug = iaa.Multiply((0.5))\n",
        "\n",
        "augmented_image = brightness_aug.augment_image(image)\n",
        "\n",
        "plt.imshow(augmented_image)\n",
        "plt.title(\"Brightness Adjusted Image\")\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rdpaRY1nLuRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Option 4: Random Noise\n",
        "\n",
        "noise_aug = iaa.AdditiveGaussianNoise(scale=(100)) # standard deviation fixed at 100\n",
        "\n",
        "augmented_image = noise_aug.augment_image(image)\n",
        "\n",
        "plt.imshow(augmented_image)\n",
        "plt.title(\"Image with Gaussian Noise\")\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9V3x2YEuKbyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Distortions (Elastic Transformation)\n",
        "\n",
        "elastic_aug = iaa.ElasticTransformation(alpha=100, sigma=3) # alpha contols level of distortions, sigma controls focus on unnoticable distortions\n",
        "\n",
        "augmented_image = elastic_aug.augment_image(image)\n",
        "\n",
        "plt.imshow(augmented_image)\n",
        "plt.title(\"Elastic Transformed Image\")\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hQ-aZkdkMFXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Data Augmentation"
      ],
      "metadata": {
        "id": "GsAmW60AH2LL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs"
      ],
      "metadata": {
        "id": "Om51jfubDeYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies\n",
        "!pip install --upgrade gensim --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install sacremoses --quiet\n",
        "!pip install nlpaug --quiet"
      ],
      "metadata": {
        "id": "GcR6g_O_J7GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Models\n",
        "from nlpaug.util.file.download import DownloadUtil\n",
        "\n",
        "# DownloadUtil.download_word2vec(dest_dir = '.')\n",
        "# Possible values are ‘wiki-news-300d-1M’, ‘wiki-news-300d-1M-subword’, ‘crawl-300d-2M’ and ‘crawl-300d-2M-subword’\n",
        "\n",
        "DownloadUtil.download_fasttext(dest_dir = '.', model_name = 'crawl-300d-2M')\n",
        "\n",
        "# for synonym replacement\n",
        "# DownloadUtil.download_glove(dest_dir = '.', model_name = 'glove.6B')"
      ],
      "metadata": {
        "id": "TxL8dqJDH4Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config Env"
      ],
      "metadata": {
        "id": "rhdijSqrDg3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports (restart runtime)\n",
        "import gensim\n",
        "print(gensim.__version__)\n",
        "\n",
        "import transformers\n",
        "\n",
        "import sacremoses # for back translation tokenizer\n",
        "\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as nafc\n",
        "from nlpaug.util import Action\n"
      ],
      "metadata": {
        "id": "B7gsPk4gKXl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example Sentence for Augmentation\n",
        "\n",
        "TEXT = \"I have been riding my scooter to the store everyday to get bananas.\" #@param"
      ],
      "metadata": {
        "id": "MhAlqyypBeGi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Options for NLP Data Augmentation"
      ],
      "metadata": {
        "id": "Obt9YIuXHy-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Option 1: Replace words with other most similar words\n",
        "\n",
        "aug = naw.WordEmbsAug(\n",
        "  model_type = \"word2vec\",\n",
        "  model_path = \"GoogleNews-vectors-negative300.bin\",\n",
        "  action = \"substitute\",  # \"insert\" is another option that doesn't remove og words\n",
        "  aug_p = 0.25 # probability of token selection for replacement\n",
        "  )\n",
        "\n",
        "## Other Models you can use\n",
        "# aug = naw.WordEmbsAug(\n",
        "#   model_type = 'fasttext',\n",
        "#   model_path = 'crawl-300d-2M.vec',\n",
        "#   action = \"insert\"\n",
        "#   )\n",
        "\n",
        "# aug = naw.WordEmbsAug(\n",
        "#   model_type = 'glove',\n",
        "#   model_path = 'glove.6B.300d.txt',\n",
        "#   action = \"substitute\"\n",
        "#   )\n",
        "\n",
        "\n",
        "# Augment the text\n",
        "augmented_text = aug.augment(TEXT)\n",
        "print(f\"Original:         {TEXT}\\n\")\n",
        "print(f\"Augmented Text:   {augmented_text}\")"
      ],
      "metadata": {
        "id": "Btf7-QPfCY7C",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Option 2: Add context words based on nearest embeddings\n",
        "\n",
        "aug = naw.ContextualWordEmbsAug(\n",
        "  model_path = 'bert-base-uncased',\n",
        "  action = \"insert\",\n",
        "  aug_p = 0.25\n",
        "  )\n",
        "\n",
        "augmented_text = aug.augment(TEXT)\n",
        "\n",
        "print(f\"Original:         {TEXT}\\n\")\n",
        "print(f\"Augmented Text:   {augmented_text}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RglLFosNFSx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Option 3: Synonym Replacement\n",
        "\n",
        "aug = naw.SynonymAug(\n",
        "    aug_src = \"wordnet\",\n",
        "    aug_max = 3 # aug_p words too but this allows us to limit how many words are changed\n",
        "    )\n",
        "augmented_text = aug.augment(TEXT)\n",
        "\n",
        "print(f\"Original:         {TEXT}\\n\")\n",
        "print(f\"Augmented Text:   {augmented_text}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d67mr9IyFywd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Option 4: Translations (and back translation)\n",
        "\n",
        "back_translation_aug = naw.BackTranslationAug(\n",
        "    from_model_name = 'facebook/wmt19-en-de',\n",
        "    to_model_name = 'facebook/wmt19-de-en'\n",
        ")\n",
        "\n",
        "augmented_text = back_translation_aug.augment(TEXT)\n",
        "\n",
        "print(f\"Original:         {TEXT}\\n\")\n",
        "print(f\"Augmented Text:   {augmented_text}\")"
      ],
      "metadata": {
        "id": "m8_TgewjWul_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}